FROM rhel7:7-released as build

RUN yum -y install wget rh-maven36 \
  && wget https://github.com/AdoptOpenJDK/openjdk8-binaries/releases/download/jdk8u262-b05_openj9-0.21.0-m1/OpenJDK8U-jdk_s390x_linux_openj9_8u262b05_openj9-0.21.0-m1.tar.gz \
  && tar -xzf OpenJDK8U-jdk_s390x_linux_openj9_8u262b05_openj9-0.21.0-m1.tar.gz \
  && mkdir /usr/local/java \
  && mv /jdk8u262-b05 /usr/local/java \
  && mkdir /usr/local/java/jdk8u262-b05/lib/security \
  && cp /usr/local/java/jdk8u262-b05/jre/lib/security/cacerts /usr/local/java/jdk8u262-b05/lib/security/ \
  && chmod 777 /usr/local/java/jdk8u262-b05/lib/security/cacerts

#RUN yum -y install rh-maven36 \
#  && rpm -e --nodeps copy-jdk-configs-3.3-10.el7_5.noarch java-1.8.0-openjdk-headless-1.8.0.252.b09-2.el7_8.s390x \
#  java-1.8.0-ibm-1.8.0.6.10-1jpp.1.el7.s390x

ENV JAVA_HOME /usr/local/java/jdk8u262-b05
ENV PATH $PATH:$JAVA_HOME/bin
ENV CLASSPATH $JAVA_HOME/lib


RUN yum -y install --setopt=skip_missing_names_on_install=False \
    patch \
    git \
    lzo-devel zlib-devel gcc gcc-c++ make autoconf automake libtool openssl-devel fuse-devel \
    cmake3 \
    && yum clean all \
    && rm -rf /var/cache/yum

RUN ln -s /usr/bin/cmake3 /usr/bin/cmake

# protobuf 2.5
RUN mkdir -p /opt/protobuf-src && \
    curl -L -s -S \
      https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz \
      -o /opt/protobuf.tar.gz && \
    tar xzf /opt/protobuf.tar.gz --strip-components 1 -C /opt/protobuf-src
RUN cd /opt/protobuf-src && \
    curl -L -s -S \
      https://raw.githubusercontent.com/google/protobuf/3.3.x/src/google/protobuf/stubs/atomicops_internals_generic_gcc.h \
      -o src/google/protobuf/stubs/atomicops_internals_generic_gcc.h && \
    sed -in '185i \#elif defined(GOOGLE_PROTOBUF_ARCH_S390)\n\#include <google/protobuf/stubs/atomicops_internals_generic_gcc.h>' \
      src/google/protobuf/stubs/atomicops.h && \
    sed -in '60i \#elif defined(__s390x__)\n\#define GOOGLE_PROTOBUF_ARCH_S390 1\n\#define GOOGLE_PROTOBUF_ARCH_64_BIT 1' \
      src/google/protobuf/stubs/platform_macros.h && \
    ./configure --prefix=/opt/protobuf && make install
ENV PROTOBUF_HOME /opt/protobuf
ENV PATH "${PATH}:/opt/protobuf/bin"

RUN mkdir /build
COPY .git /build/.git
COPY hadoop-yarn-project /build/hadoop-yarn-project
COPY hadoop-assemblies /build/hadoop-assemblies
COPY hadoop-project /build/hadoop-project
COPY hadoop-common-project /build/hadoop-common-project
COPY hadoop-cloud-storage-project /build/hadoop-cloud-storage-project
COPY hadoop-project-dist /build/hadoop-project-dist
COPY hadoop-maven-plugins /build/hadoop-maven-plugins
COPY hadoop-dist /build/hadoop-dist
COPY hadoop-minicluster /build/hadoop-minicluster
COPY hadoop-mapreduce-project /build/hadoop-mapreduce-project
COPY hadoop-tools /build/hadoop-tools
COPY hadoop-hdfs-project /build/hadoop-hdfs-project
COPY hadoop-client-modules /build/hadoop-client-modules
COPY hadoop-build-tools /build/hadoop-build-tools
COPY dev-support /build/dev-support
COPY pom.xml /build/pom.xml
COPY LICENSE.txt /build/LICENSE.txt
COPY BUILDING.txt /build/BUILDING.txt
COPY NOTICE.txt /build/NOTICE.txt
COPY README.txt /build/README.txt


ENV CMAKE_C_COMPILER=gcc CMAKE_CXX_COMPILER=g++

# To avoid java out of memory error
# ENV MAVEN_OPTS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1 -Xmx1024m"
ENV MAVEN_OPTS="-Xmx1024m"

# build hadoop
RUN scl enable rh-maven36 'cd /build && mvn -B -e -Dtest=false -DskipTests -Dmaven.javadoc.skip=true clean package -Pdist,native -Dtar'

# Install prometheus-jmx agent
RUN scl enable rh-maven36 'mvn dependency:get -Dartifact=io.prometheus.jmx:jmx_prometheus_javaagent:0.3.1:jar -Ddest=/build/jmx_prometheus_javaagent.jar'
# Get gcs-connector for Hadoop
RUN scl enable rh-maven36 'cd /build && mvn dependency:get -Dartifact=com.google.cloud.bigdataoss:gcs-connector:hadoop3-2.0.0-RC2:jar:shaded && mv $HOME/.m2/repository/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.0.0-RC2/gcs-connector-hadoop3-2.0.0-RC2-shaded.jar /build/gcs-connector-hadoop3-2.0.0-RC2-shaded.jar'

FROM brew-pulp-docker01.web.prod.ext.phx2.redhat.com:8888/openshift/ose-base:latest

RUN set -x; yum install --setopt=skip_missing_names_on_install=False -y \
        wget \
        curl \
        git \
        less  \
        procps \
        net-tools \
        bind-utils \
        which \
        golang \
        jq \
        jq-devel \
        oniguruma-5.9.5 \
        oniguruma-devel-5.9.5 \
        rsync \
        openssl \
    && yum clean all \
    && rm -rf /tmp/* /var/tmp/*

RUN wget https://github.com/AdoptOpenJDK/openjdk8-binaries/releases/download/jdk8u262-b05_openj9-0.21.0-m1/OpenJDK8U-jdk_s390x_linux_openj9_8u262b05_openj9-0.21.0-m1.tar.gz \
  && tar -xzvf OpenJDK8U-jdk_s390x_linux_openj9_8u262b05_openj9-0.21.0-m1.tar.gz \
  && mkdir /usr/local/java \
  && mv /jdk8u262-b05 /usr/local/java \
  && mkdir /usr/local/java/jdk8u262-b05/lib/security \
  && cp /usr/local/java/jdk8u262-b05/jre/lib/security/cacerts /usr/local/java/jdk8u262-b05/lib/security/ \
  && chmod 777 /usr/local/java/jdk8u262-b05/lib/security/cacerts

ENV JAVA_HOME /usr/local/java/jdk8u262-b05/jre
ENV PATH $PATH:$JAVA_HOME/bin
ENV CLASSPATH $JAVA_HOME/lib


# install faq
RUN git clone -b 0.0.6 https://github.com/jzelinskie/faq.git && cd faq && \
        make build SKIP_VALIDATE=true FAQ_LINK_STATIC=false GO_LD_FLAGS='-compressdwarf=false -linkmode external -extldflags "-v"' && \
        make install

# install tini
#RUN curl -fSLs https://github.com/krallin/tini/releases/download/v0.18.0/tini-s390x -o /tini
#RUN curl -fSLs https://github.com/krallin/tini/releases/download/v0.18.0/tini-static-s390x -o /tini-static
ENV TINI_VERSION v0.18.0
ADD https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini /usr/bin/tini
RUN chmod +x /usr/bin/tini

#ENV JAVA_HOME=/etc/alternatives/jre

ENV HADOOP_VERSION 3.1.1

ENV HADOOP_HOME=/opt/hadoop
ENV HADOOP_LOG_DIR=$HADOOP_HOME/logs
ENV HADOOP_CLASSPATH=$HADOOP_HOME/share/hadoop/tools/lib/*
ENV HADOOP_CONF_DIR=/etc/hadoop
ENV PROMETHEUS_JMX_EXPORTER /opt/jmx_exporter/jmx_exporter.jar
ENV PATH=$HADOOP_HOME/bin:$PATH

COPY --from=build /build/hadoop-dist/target/hadoop-$HADOOP_VERSION $HADOOP_HOME
COPY --from=build /build/jmx_prometheus_javaagent.jar $PROMETHEUS_JMX_EXPORTER
COPY --from=build /build/gcs-connector-hadoop3-2.0.0-RC2-shaded.jar $HADOOP_HOME/share/hadoop/tools/lib/gcs-connector-hadoop3-shaded.jar
WORKDIR $HADOOP_HOME

# remove unnecessary doc/src files
RUN rm -rf ${HADOOP_HOME}/share/doc \
    && for dir in common hdfs mapreduce tools yarn; do \
         rm -rf ${HADOOP_HOME}/share/hadoop/${dir}/sources; \
       done \
    && rm -rf ${HADOOP_HOME}/share/hadoop/common/jdiff \
    && rm -rf ${HADOOP_HOME}/share/hadoop/mapreduce/lib-examples \
    && rm -rf ${HADOOP_HOME}/share/hadoop/yarn/test \
    && find ${HADOOP_HOME}/share/hadoop -name *test*.jar | xargs rm -rf

RUN ln -s $HADOOP_HOME/etc/hadoop $HADOOP_CONF_DIR
RUN mkdir -p $HADOOP_LOG_DIR

# https://docs.oracle.com/javase/7/docs/technotes/guides/net/properties.html
# Java caches dns results forever, don't cache dns results forever:
RUN sed -i '/networkaddress.cache.ttl/d' $JAVA_HOME/lib/security/java.security
RUN sed -i '/networkaddress.cache.negative.ttl/d' $JAVA_HOME/lib/security/java.security
RUN echo 'networkaddress.cache.ttl=0' >> $JAVA_HOME/lib/security/java.security
RUN echo 'networkaddress.cache.negative.ttl=0' >> $JAVA_HOME/lib/security/java.security

# imagebuilder expects the directory to be created before VOLUME
RUN mkdir -p /hadoop/dfs/data /hadoop/dfs/name

# to allow running as non-root
RUN chown -R 1002:0 $HADOOP_HOME /hadoop $HADOOP_CONF_DIR $JAVA_HOME/lib/security/cacerts && \
    chmod -R 774 $HADOOP_HOME /hadoop $HADOOP_CONF_DIR $JAVA_HOME/lib/security/cacerts
RUN chown -R 1002:0 $HADOOP_HOME /hadoop $HADOOP_CONF_DIR && \
    chmod -R 774 $HADOOP_HOME /hadoop $HADOOP_CONF_DIR 

VOLUME /hadoop/dfs/data /hadoop/dfs/name

USER 1002

LABEL io.k8s.display-name="OpenShift Hadoop" \
      io.k8s.description="This is an image used by operator-metering to to install and run HDFS." \
      io.openshift.tags="openshift" \
      maintainer="AOS Operator Metering <sd-operator-metering@redhat.com>"
